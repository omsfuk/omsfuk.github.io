-----------------------
title: Java特种兵 之 CPU的那些事
tags: java
-----------------------
## 多核

*  CPU可以一次做几件事，所以他会有一个小的Cache区域，将这些内容暂时Cache住，这样距离处理器越近，操作的延迟就越小，整体效率自然就越高。

*  计算机的思想模型来源于现实的抽象。

*  在多核的Cache中，对于某些数据Cache后，数据在“写入”和“读取”的时候必须满足一些规范，通常叫做“缓存一致性协议“。通过这种规范来实现架构，用以满足多个CPU对同一个变量修改时，相互之间都是知道的。不过，它并不能保证所有的数据都是这样的。因为这样做的开销是巨大的，所以在某些时候是允许不一致的情况发生的。

*  在Java程序中“栈空间”也是类似的，当程序的局部变量中使用基本类型时，他直接在“栈”上申请了一些空间，而当使用引用来引用对象时，这些引用的空间也位于“栈”上。

*  多个CPU要发挥最大效应就是不让某些人偷懒，自然就需要一些算法来协调和管理，让请求负载均衡。

*  起初，操作系统可能是不断地定时扫描各个部件看是否有指令来，有的话就处理，但是显然这种模式会很慢，因为“知道的时候往往都晚了”，这就是所谓的“不及时”或“非实时”。后来CPU有了“中断”模型，通过中断来完成调用，貌似实时性很强，但是某些部件发起中断频率非常高（例如鼠标移动，就在不断地发送指令）。此时对中断会有一个缓冲区，由于CPU的处理速度非常快，可以再一瞬间处理大批量的请求，所以这种缓冲是不错的设计思路（在很多设计中都会用到）。

*  操作系统不希望CPU为一个“等待指令”或者是长期执行的任务使得自己“陷入困境”，比如一些I/O等待（网路I/O和磁盘I/O），它中途基本都不参与，而是以事件注册的方式来实现回调，对于某些执行时间长的任务，CPU可能会分配一些时间片来处理其他的任务）。

*  当多个CPU在同一台计算机中出现的时候，会出现什么情况呢？是大家一起去抢指令？还是由一个CPU来分配指令？亦或是某些CPU专门管理某一块区域的指令？

*  现在来说“大家一起去枪指令”，这种方式是不多见的，只是在某些系统的设计中有多进程模式，让多个进程监听同一个端口，当这个端口得到信号时，可能多个进程同时被唤醒的现象还是存在的，我们通常称之为“惊群”。
而“由一个CPU来分配指令”，这种方式也存在，那这样会不会让这个CPU很忙？也就是这个CPU会不会出现相对“飚”高的现象，尤其是有大量请求的时候？没错，它也有曲线，只是通常情况下问题不会太大，而且它至少实现了调度，在有些时候可以划分下“领土”，使资源隔离是比较“靠谱”的。

### Cache Line
*  Cache Line就是Cache 一行。它将“连续的一段内存区域”进行Cache，不是每次就Cache一个内存单元，而是一系列内存单元。在计算机中，通产以连续64字节为基本单位进行Cache操作。

*  Java在内存中分配是先分配第一维（或者说Java没有真正意义上的二位数组），然后再分配多个第二维子数组，也就是说a [0][x] 和a [0][x] 是位于两个不同数组上的，空间自然不会在一起。

*  CPU Cache时是按照连续内存空间进行的，但是对内存进行了修改，回写时不是按照行进行。

### 缓存一致性原则
*   是什么：
    * 当有多个来自于内存中的同一份数据Cache在多个CPU中，且要求这些数据的读写一致时，多个CPU之间就需要遵循缓存共享的一致性原则。

    * 这种模型，在CPU上的实现就对应于多个CPU得到同一个内存单元都有自己的一份拷贝，当某个CPU修改他们的共享数据时，需要通知另一个CPU已经修改。

    * 内存单元有修改（Modified）、独占（Exclusive）、共享（Shared）、失效（Invalid）多种状态，多个CPU通过总线相互连接，每个CPU的Cache处理器除了要去响应本身所对应的CPU的读写操作外，还需要监听总线上其他CPU的读写操作，通过监听对自己的Cache做相应的处理，形成了一种虚共享，这个协议叫做MESI协议。

    * 作为Java程序员，不用纠结于太多的十分深入的内核细节，但是要知道它是存在的，他会对程序产生怎样的影响，以及如何利用好它的原理。

### 上下文切换
*  进程比线程有更多的开销，进程独立向OS申请资源，而线程是共享进程的资源，其实就状态来讲，他们的区别并不是特别大，各有好处和坏处。

*  目前CPU调度的最基本单位是线程，Java也是基于多线程模式的，而非多进程模式，因为资源共享，在Java中一个线程可以让一个静态的数据放大，将一个JVM进程直挂死掉，这种情况在多进程模式中不会发生。

*  现在许多开源的日志工具（如Log4j）都是采用异步模式去实现日志写操作，而程序通常不直接参与这个写操作，那么大部分线程就可以直接完成处理。他的实现方式是，日志写操作只是将日志写入一个消息队列中，有单独的线程来完成写操作，如果用堵塞的方式就会阻塞当前执行业务操作的这个线程，这样也同时降低了许多I/O竞争，将许多随机写操作变成了顺序写操作，从而可以提升平均性能。

### 并发与征用
*  只要是服务器端程序，迟早会遇到并发。

*  配置线程池时，通常合适就行。什么样才算合适呢？根据实际场景而定，并非是一个绝对值，在CPU密集型系统中理想状态下的线程数是CPU数±1，目的是让CPU转起来。
而在I/O密集型系统中，本身就需要大量的线程，并不在乎上下文切换的开销。

*  大多数系统会有一些I/O也有部分CPU时间，那么他们到底应该如何配置线程数呢？我们做一个简单的分析。
    1.  系统CPU密集度

        * 一般系统分为计算密集型和I/O密集型两种。所谓计算密集型就是指系统大部分时间是在做程序正常的计算任务，例如数字运算、赋值、分配内存、内存拷贝、循环、查找、排序等，这些处理都需要CPU来完成，所以也叫CPU密集型。

        * I/O密集型是指系统大部分时间是在做I/O交互，而这个时间线程不会占用CPU来处理（但是通常会在系统中记录下这个线程正在等待I/O，以便I/O数据返回时，系统可以将其激活，被CPU再次调度）。换句话说，在这个时间范围内，可以由其他的线程来使用CPU，因此就可以多配置一些线程。

    2.  关键程序的各项时间比例

        * 其一，普通常规的操作，理论上我们认为这些操作都需要CPU调度来处理（不论是否需要将数据从主内存加载到栈或者加载到CPU的Cache中，总之需要CPU来处理），在最理想的情况下，大牛们建议将线程数设置为CPU数±1，因为这样设置后，理论上是没有线程上下文切换的，或者说发生上下文切换的概率会小得多（排除系统本身及其他的进程也需要使用CPU）。
        * 其二，I/O操作（包括网络I/O、磁盘I/O、键盘I/O、屏幕输出I/O），很多人会说：如果不做系统之间的调用就不会用到网络I/O吧。其实不然，数据库、缓存操作也是网络I/O。  
        例如，系统中一段比较“关键”的程序访问总共花费了120ms，I/O操作占用了100ms，那么意味着在这100ms时间内CPU是可以被其他线程访问的。此时，这个程序在单核系统中的线程数理论上可以设置为6，在多核系统中  自然是乘以CPU的个数。一般会在这数字上下浮动。  
        此时得到的仅仅是理论数字，可能存在很多的实际情况未考虑到，所以需要通过测试来得到更准确的结果，一般关键程序决定大致的配置数量。  
        * 其三，“锁”，也就是临界区的范围，前面提到了它有粒度，在这个区域内不论有多少个CPU，也无法同时进入。因此这部分不好计算，要根据关键程序本身来计算，如果在锁内部发生了I/O操作，或者有大量的循环、递归处理，那么就必须等待这些操作处理完成后才能有下一个线程进入处理。如果这段程序不是关键程序，那么有些时候我们可以忽略它，但如果是关键程序（也就是被频繁访问的程序），在系统真正并发时，就会导致很多的线程阻塞在这个位置。此时计算线程数，首先要看这个锁的对象是不是静态对象或Class，如果是，则可以认为是一个JVM进程全局锁，那么无论配置多少个线程效果都是一样的（线程多的时候其余的线程还得等待与分配，效率可能会更差），并且在这个时候不能乘以CPU的个数，因为
        * 全局的，多核也无法并行处理临界区的内容，和CPU个数是无关的。如果对锁的粒度、范围作了优化，也许可以根据分段规则、细粒度规则，乘以这个粒度级别（例如ConcurrentHashMap内部默认分解为16个Segment，数据都是先查找Segment，在在内部加锁，因此在理想情况下，锁粒度可以降低16倍，那么自然的应该允许16个并行。当然不排除由于热点问题，导致某些Segment上的请求更多，而某些Segment上的没有征用。最坏的情况就是所有的请求分布到了同一个Segment上）。在划分粒度后，这个值自然不那么离谱了，因为最理想情况与最坏情况和实际情况十分密切。这个值只能做出一个预估值，在实际场景中要先看具体的处理方法在进行估算，这是最靠谱的（所谓的公式也只是告知底层原理的另一种说法，但是实际情况往往是千变万化的，很多时候我们甚至希望系统有一些自适应能力，根据实际情况自动来做一些调节）。


    3.  JVM本身的调节
        * 不论CPU跑的多么快，如果JVM“hold不住”这个寄走，在不断地GC操作，或者因为其他因素跑的“慢死”，那么怎么配置线程池，系统的性能也不可能上来。 ## 多核

*  CPU可以一次做几件事，所以他会有一个小的Cache区域，将这些内容暂时Cache住，这样距离处理器越近，操作的延迟就越小，整体效率自然就越高。

*  计算机的思想模型来源于现实的抽象。

*  在多核的Cache中，对于某些数据Cache后，数据在“写入”和“读取”的时候必须满足一些规范，通常叫做“缓存一致性协议“。通过这种规范来实现架构，用以满足多个CPU对同一个变量修改时，相互之间都是知道的。不过，它并不能保证所有的数据都是这样的。因为这样做的开销是巨大的，所以在某些时候是允许不一致的情况发生的。

*  在Java程序中“栈空间”也是类似的，当程序的局部变量中使用基本类型时，他直接在“栈”上申请了一些空间，而当使用引用来引用对象时，这些引用的空间也位于“栈”上。

*  多个CPU要发挥最大效应就是不让某些人偷懒，自然就需要一些算法来协调和管理，让请求负载均衡。

*  起初，操作系统可能是不断地定时扫描各个部件看是否有指令来，有的话就处理，但是显然这种模式会很慢，因为“知道的时候往往都晚了”，这就是所谓的“不及时”或“非实时”。后来CPU有了“中断”模型，通过中断来完成调用，貌似实时性很强，但是某些部件发起中断频率非常高（例如鼠标移动，就在不断地发送指令）。此时对中断会有一个缓冲区，由于CPU的处理速度非常快，可以再一瞬间处理大批量的请求，所以这种缓冲是不错的设计思路（在很多设计中都会用到）。

*  操作系统不希望CPU为一个“等待指令”或者是长期执行的任务使得自己“陷入困境”，比如一些I/O等待（网路I/O和磁盘I/O），它中途基本都不参与，而是以事件注册的方式来实现回调，对于某些执行时间长的任务，CPU可能会分配一些时间片来处理其他的任务）。

*  当多个CPU在同一台计算机中出现的时候，会出现什么情况呢？是大家一起去抢指令？还是由一个CPU来分配指令？亦或是某些CPU专门管理某一块区域的指令？

*  现在来说“大家一起去枪指令”，这种方式是不多见的，只是在某些系统的设计中有多进程模式，让多个进程监听同一个端口，当这个端口得到信号时，可能多个进程同时被唤醒的现象还是存在的，我们通常称之为“惊群”。
而“由一个CPU来分配指令”，这种方式也存在，那这样会不会让这个CPU很忙？也就是这个CPU会不会出现相对“飚”高的现象，尤其是有大量请求的时候？没错，它也有曲线，只是通常情况下问题不会太大，而且它至少实现了调度，在有些时候可以划分下“领土”，使资源隔离是比较“靠谱”的。

### Cache Line
*  Cache Line就是Cache 一行。它将“连续的一段内存区域”进行Cache，不是每次就Cache一个内存单元，而是一系列内存单元。在计算机中，通产以连续64字节为基本单位进行Cache操作。

*  Java在内存中分配是先分配第一维（或者说Java没有真正意义上的二位数组），然后再分配多个第二维子数组，也就是说a [0][x] 和a [0][x] 是位于两个不同数组上的，空间自然不会在一起。

*  CPU Cache时是按照连续内存空间进行的，但是对内存进行了修改，回写时不是按照行进行。

### 缓存一致性原则
*   是什么：
    * 当有多个来自于内存中的同一份数据Cache在多个CPU中，且要求这些数据的读写一致时，多个CPU之间就需要遵循缓存共享的一致性原则。

    * 这种模型，在CPU上的实现就对应于多个CPU得到同一个内存单元都有自己的一份拷贝，当某个CPU修改他们的共享数据时，需要通知另一个CPU已经修改。

    * 内存单元有修改（Modified）、独占（Exclusive）、共享（Shared）、失效（Invalid）多种状态，多个CPU通过总线相互连接，每个CPU的Cache处理器除了要去响应本身所对应的CPU的读写操作外，还需要监听总线上其他CPU的读写操作，通过监听对自己的Cache做相应的处理，形成了一种虚共享，这个协议叫做MESI协议。

    * 作为Java程序员，不用纠结于太多的十分深入的内核细节，但是要知道它是存在的，他会对程序产生怎样的影响，以及如何利用好它的原理。

### 上下文切换
*  进程比线程有更多的开销，进程独立向OS申请资源，而线程是共享进程的资源，其实就状态来讲，他们的区别并不是特别大，各有好处和坏处。

*  目前CPU调度的最基本单位是线程，Java也是基于多线程模式的，而非多进程模式，因为资源共享，在Java中一个线程可以让一个静态的数据放大，将一个JVM进程直挂死掉，这种情况在多进程模式中不会发生。

*  现在许多开源的日志工具（如Log4j）都是采用异步模式去实现日志写操作，而程序通常不直接参与这个写操作，那么大部分线程就可以直接完成处理。他的实现方式是，日志写操作只是将日志写入一个消息队列中，有单独的线程来完成写操作，如果用堵塞的方式就会阻塞当前执行业务操作的这个线程，这样也同时降低了许多I/O竞争，将许多随机写操作变成了顺序写操作，从而可以提升平均性能。

### 并发与征用
*  只要是服务器端程序，迟早会遇到并发。

*  配置线程池时，通常合适就行。什么样才算合适呢？根据实际场景而定，并非是一个绝对值，在CPU密集型系统中理想状态下的线程数是CPU数±1，目的是让CPU转起来。
而在I/O密集型系统中，本身就需要大量的线程，并不在乎上下文切换的开销。

*  大多数系统会有一些I/O也有部分CPU时间，那么他们到底应该如何配置线程数呢？我们做一个简单的分析。
    1.  系统CPU密集度

        * 一般系统分为计算密集型和I/O密集型两种。所谓计算密集型就是指系统大部分时间是在做程序正常的计算任务，例如数字运算、赋值、分配内存、内存拷贝、循环、查找、排序等，这些处理都需要CPU来完成，所以也叫CPU密集型。

        * I/O密集型是指系统大部分时间是在做I/O交互，而这个时间线程不会占用CPU来处理（但是通常会在系统中记录下这个线程正在等待I/O，以便I/O数据返回时，系统可以将其激活，被CPU再次调度）。换句话说，在这个时间范围内，可以由其他的线程来使用CPU，因此就可以多配置一些线程。

    2.  关键程序的各项时间比例

        * 其一，普通常规的操作，理论上我们认为这些操作都需要CPU调度来处理（不论是否需要将数据从主内存加载到栈或者加载到CPU的Cache中，总之需要CPU来处理），在最理想的情况下，大牛们建议将线程数设置为CPU数±1，因为这样设置后，理论上是没有线程上下文切换的，或者说发生上下文切换的概率会小得多（排除系统本身及其他的进程也需要使用CPU）。
        * 其二，I/O操作（包括网络I/O、磁盘I/O、键盘I/O、屏幕输出I/O），很多人会说：如果不做系统之间的调用就不会用到网络I/O吧。其实不然，数据库、缓存操作也是网络I/O。  
        例如，系统中一段比较“关键”的程序访问总共花费了120ms，I/O操作占用了100ms，那么意味着在这100ms时间内CPU是可以被其他线程访问的。此时，这个程序在单核系统中的线程数理论上可以设置为6，在多核系统中  自然是乘以CPU的个数。一般会在这数字上下浮动。  
        此时得到的仅仅是理论数字，可能存在很多的实际情况未考虑到，所以需要通过测试来得到更准确的结果，一般关键程序决定大致的配置数量。  
        * 其三，“锁”，也就是临界区的范围，前面提到了它有粒度，在这个区域内不论有多少个CPU，也无法同时进入。因此这部分不好计算，要根据关键程序本身来计算，如果在锁内部发生了I/O操作，或者有大量的循环、递归处理，那么就必须等待这些操作处理完成后才能有下一个线程进入处理。如果这段程序不是关键程序，那么有些时候我们可以忽略它，但如果是关键程序（也就是被频繁访问的程序），在系统真正并发时，就会导致很多的线程阻塞在这个位置。此时计算线程数，首先要看这个锁的对象是不是静态对象或Class，如果是，则可以认为是一个JVM进程全局锁，那么无论配置多少个线程效果都是一样的（线程多的时候其余的线程还得等待与分配，效率可能会更差），并且在这个时候不能乘以CPU的个数，因为
        * 全局的，多核也无法并行处理临界区的内容，和CPU个数是无关的。如果对锁的粒度、范围作了优化，也许可以根据分段规则、细粒度规则，乘以这个粒度级别（例如ConcurrentHashMap内部默认分解为16个Segment，数据都是先查找Segment，在在内部加锁，因此在理想情况下，锁粒度可以降低16倍，那么自然的应该允许16个并行。当然不排除由于热点问题，导致某些Segment上的请求更多，而某些Segment上的没有征用。最坏的情况就是所有的请求分布到了同一个Segment上）。在划分粒度后，这个值自然不那么离谱了，因为最理想情况与最坏情况和实际情况十分密切。这个值只能做出一个预估值，在实际场景中要先看具体的处理方法在进行估算，这是最靠谱的（所谓的公式也只是告知底层原理的另一种说法，但是实际情况往往是千变万化的，很多时候我们甚至希望系统有一些自适应能力，根据实际情况自动来做一些调节）。


    3.  JVM本身的调节
        * 不论CPU跑的多么快，如果JVM“hold不住”这个寄走，在不断地GC操作，或者因为其他因素跑的“慢死”，那么怎么配置线程池，系统的性能也不可能上来。
